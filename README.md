# Smart Dashboard ETL-pipline

В данном репозитории представлен ETL-пайплайн для обработки данных о расходах автопарка, которые используются в дашборде. Пайплайн обрабатывает загрузку данных из CSV-файлов или баз данных, выполняет обнаружение аномалий в расходах, генерирует рекомендации и подготавливает данные для визуализации и анализа.
Пайплайн построен с использованием Apache Airflow для оркестрации, с кастомными классами Python для анализа данных (fraud_finder.py, PlotDataMaker.py). Интегрируется с PostgreSQL для хранения данных.

## Ключевые возможности:

 - Загрузка данных: Извлечение данных из локальных файлов или баз данных клиентов, нормализация столбцов и вставка в центральную базу PostgreSQL.
 - Обнаружение аномалий: Идентификация аномалий, таких как высокие зарплаты, отклонения от бюджета, неэффективность топлива и высокие штрафы.
 - Анализ и рекомендации: Генерация инсайтов, таких как отклонения расходов от рыночных средних, различные оценки эффективности, прогнозирование с помощью Prophet.
 - Подготовка данных для дашборда: Агрегация данных для графиков и хранение результатов в формате JSON для интеграции с дашбордом.
 - Логика по отраслям: Кастомная обработка для разных отраслей, включая специализированные категории расходов.
 - Планирование выполнения: DAG для загрузки и обновления данных (load_data_DAG_3_tables.py) запускается по триггеру входа клиента в дашборд, если у него есть привязанная база данных, в другом случае по триггеру подключения клиентской базы данных или загрузки файла(ов) с данными; DAG для выявления аномалий, агрегирования данных для графиков и получения рекомендаций запускается периодически каждые 3 минуты.

## Структура репозитория

 - load_data_DAG_3_tables.py: DAG Airflow для загрузки данных. Ожидает файлы во входной директории, извлекает информацию из клиентских баз данных, нормализует схемы и вставляет данные в таблицы PostgreSQL.
 - fraud_find_DAG_3_tables.py: DAG Airflow для обнаружения аномалий и анализа. Получает данные клиентов, обрабатывает таблицы расходов и транспорта, запускает fraud_finder.py и PlotDataMaker.py, сохраняет результатыв базу данных в виде JSON .
 - fraud_finder.py: Основной класс для обнаружения аномалий. Методы включают поиск высоких зарплат, отклонений от бюджета, сравнения с рынком, расчёты эффективности, прогнозирование с Prophet и генерацию рекомендаций.
 - PlotDataMaker.py: Класс для подготовки данных к визуализации. Включает методы для агрегации расходов, расчёта эффективности, простоев, сезонных штрафов и графиков по отраслям (например, топливо на км, топ-водители по штрафам).

## Требования

Python: 3.8+ (протестировано на 3.12)
Apache Airflow: 2.0+ (с провайдером PostgreSQL: pip install apache-airflow-providers-postgres)
База данных: PostgreSQL (ID соединения: postgres_connect в Airflow)
Библиотеки (установить через pip install -r requirements.txt, или вручную):

 - pandas
 - numpy
 - prophet
 - sqlalchemy
 - psutil

## Использование

Входные данные:

CSV/XLSX/JSON-файлы в /opt/airflow/input (или настраиваемая DATA_DIR) с расходами автопарка и деталями транспорта или подключение базы данных с теми же данными.

Запуск DAG загрузки данных:

 1. Запустить etl_crm_erp_pipeline_sqlalchemy_COPY_no_limits в UI Airflow.
 2. Передать client_id как параметр (через JSON-конфиг).
 3. DAG ожидает файлы в DATA_DIR, обрабатывает их и очищает после успеха.

Запуск DAG обнаружения аномалий:

 1. Запустить fraud_find_dag_3_tables в UI Airflow.
 2. Он получает всех клиентов из web.users (таблица с данными пользователей дашборда), обрабатывает данные по клиентам, выполняет анализ и сохраняет результаты JSON в таблицу fraud_json.
 3. Запланировано на запуск каждые 3 минуты (*/3 * * * *).

Выходные данные:

Результаты хранятся в PostgreSQL (таблица fraud_json) как JSON-блоки по клиентам и типам анализа.
Пример структуры JSON: Агрегированные расходы, эффективности, рекомендации, прогнозы.

Мониторинг:

Логи включают использование памяти (через psutil) и ошибки.
